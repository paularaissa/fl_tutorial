{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create a distributed histogram using Flower\n",
    "\n",
    "This introductory example of creating a distributed histogram, uses a personalized strategy to aggregate results from clients. Deep knowledge of aggregation strategies is not necessarily required to run the example. However, it will help you understand how to adapt Flower to your use case. Running this example in itself is quite easy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 0: Preparation\n",
    "\n",
    "Before we begin with any actual code, let's make sure that we have everything we need.\n",
    "\n",
    "### Instaling dependencies\n",
    "First, we should install the necessary packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Jump to the next block of code if you already installed the packages.\n",
    "\n",
    "# Linux\n",
    "!pip install -q flwr[simulation] matplotlib\n",
    "\n",
    "# MacOs\n",
    "#!pip3 install -U 'flwr[simulation]' matplotlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import flwr as fl\n",
    "from sklearn.datasets import load_iris"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is possible to switch to a runtime that has GPU acceleration enabled (on Google Colab: Runtime > Change runtime type > Hardware accelerator: GPU > Save). Note, however, that Google Colab is not always able to offer GPU acceleration. If you see an error related to GPU availability in one of the following sections, consider switching back to CPU-based execution by setting DEVICE = torch.device(\"cpu\"). If the runtime has GPU acceleration enabled, you should see the output Training on cuda, otherwise it'll say Training on cpu."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the data\n",
    "\n",
    "Federated learning can be applied to many different types of tasks across different domains. In this tutorial, we introduce federated learning by training a Logistic Regression on the popular Iris dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We simulate having multiple datasets from multiple organizations (also called the \"cross-silo\" setting in federated learning) by splitting the original Iris dataset into multiple partitions. Each partition will represent the data from a single organization. We're doing this purely for experimentation purposes.\n",
    "\n",
    "Each organization will act as a client in the federated learning system. So having 3 organizations participate in a federation means having 3 clients connected to the federated learning server.\n",
    "\n",
    "Let's now create the Federated Dataset abstraction that from flwr-datasets that partitions the Iris. We will create small training and test set for each edge device and wrap each of them into a DataLoader:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the number of clients\n",
    "NUM_CLIENTS = 3\n",
    "\n",
    "def load_data():\n",
    "    iris = load_iris()\n",
    "    # Create pandas DataFrame\n",
    "    iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "    # Add label column (flower species)\n",
    "    iris_df['species'] = iris.target\n",
    "\n",
    "    # Optional: Map species numbers to names\n",
    "    #iris_df['species'] = iris_df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "    return iris_df\n",
    "\n",
    "def partition_data(X, num_clients):\n",
    "    partition_size = len(X) // num_clients\n",
    "    partitions = [(X[i * partition_size:(i + 1) * partition_size])\n",
    "                  for i in range(num_clients)]\n",
    "    return partitions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Implementing Flower Client\n",
    "Federated Learning systems consist of a server and multiple clients. In Flower, we create clients by implementing subclasses of `flwr.client.Client` or `flwr.client.NumPyClient`. We use `NumPyClient` in this tutorial because it is easier to implement.\n",
    "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the method `fit`:\n",
    "* `fit`: Receive model parameters from the server, train the model parameters on the local data, and return the updated model parameters to the server.\n",
    "\n",
    "Our clients will use the `numpy` components to compute the histogram. Let's see a simple Flower Client implementation that brings everything together."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "class PandasClient(fl.client.NumPyClient):\n",
    "    def __init__(self, X, cid):\n",
    "        self.X = X\n",
    "        self.cid = cid\n",
    "\n",
    "    def compute_hist(self, df, col_name):\n",
    "        hist, bins = np.histogram(df[col_name])\n",
    "        return hist, bins\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        hist_list = []\n",
    "        bins_list = []\n",
    "        # Execute query locally\n",
    "        for col in self.X.columns:\n",
    "            hist, bins = self.compute_hist(self.X, col)\n",
    "            hist_list.append(hist)\n",
    "            bins_list.append(bins)\n",
    "        array_of_arrays = [hist_list, bins_list]\n",
    "\n",
    "        return array_of_arrays, len(self.X), {}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our class `PandasClient` defines how local training/evaluation will be performed and allows Flower to call the local training/evaluation through `fit` and `evaluate`. Each instance of `PandasClient` represents a *single client* in our federated learning system. Federated Learning systems have multiple clients (otherwise, there is not federated), so each client will be represent by its own instance of `PandasClient`. If we have, for example, three clients in our workload, then we'd have three instances of `PandasClient`. Flower calls `PandasClient.fit` on the respective instance when the server selects a particular client for training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using the Virtual Client Engine\n",
    "\n",
    "In this notebook, we are simulating a federated learning system with 3 clients on a single machine. This means that the server and all 3 clients will live on a single machine and share resources as CPU, GPU, and memory. Having 3 clients would mean having 3 instances of `PandasClient` in memory. Doing this on a single machine can quickly exhaust the available memory resources, even if only a subset of this clients participates in a single round of federated learning.\n",
    "\n",
    "In addition to the regular capabilities where server and clients run on multiple machines, Flower, therefore provides  simulation capabilities that create `PandasClient` instances only when they are actually necessary for training or evaluation. To enable clients the Flower framework to create clients when necessary, we need to implement a function called `client_fn` that creates a `PandasClient` instance on demand. Flower calls `client_fn` whenever it needs an instance of one particular client to call `fit` or `evaluate` (those instances are usually discarded after use, so they should not keep any local state). Clients are identified by a client ID, or short `cid`. The `cid` can be clients, as can be seen below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> fl.client.Client:\n",
    "    X = load_data() # Load data\n",
    "    num_clients = NUM_CLIENTS  # Number of clients should match the number of partitions\n",
    "    partitions = partition_data(X, num_clients) # Create data partitions\n",
    "\n",
    "    partition_id = int(cid) # Associate the partition id to client id (cid)\n",
    "    # Each client gets a different X_train and y_train, so each client will train and test on their unique data\n",
    "    X = partitions[partition_id]\n",
    "\n",
    "    # Create a single Flower client representing a single organization/device\n",
    "    return PandasClient(X, cid).to_client() #for Flower version > 1.8\n",
    "    # return PandasClient(X, cid) #for Flower version < 1.8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Create the Strategy\n",
    "\n",
    "Let us overwrite the `configure_fit` method so that it passes a higher learning rate (potentially also other hyperparameters) to the optimizer of a fraction of the clients. We will keep the sampling of the clients as it is in FedAvg and then change the configuration dictionary (one of the FitIns attributes). The aggregation strategy should be implemented using the method `aggregate_fit`. Since we are aggregating histograms, each client transfers only the frequencies and bins. The server sums such values and draws the aggregated histogram."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy import Strategy\n",
    "\n",
    "\n",
    "class AggregateHistogram(Strategy):\n",
    "    def initialize_parameters(\n",
    "            self, client_manager: Optional[ClientManager] = None\n",
    "    ) -> Optional[Parameters]:\n",
    "        return None\n",
    "\n",
    "    def configure_fit(\n",
    "            self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        config = {}\n",
    "        fit_ins = FitIns(parameters, config)\n",
    "        clients = client_manager.sample(num_clients=NUM_CLIENTS, min_num_clients=2)\n",
    "        return [(client, fit_ins) for client in clients]\n",
    "\n",
    "    def aggregate_fit(\n",
    "            self,\n",
    "            server_round: int,\n",
    "            results: List[Tuple[ClientProxy, FitRes]],\n",
    "            failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        # Get results from fit\n",
    "        # Convert results\n",
    "        values_aggregated = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters)) for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        sepal_length_agg_hist = 0\n",
    "        sepal_width_agg_hist = 0\n",
    "\n",
    "        sepal_length_agg_bin = 0\n",
    "        sepal_width_agg_bin = 0\n",
    "\n",
    "        # For simplification, we are only using the first two columns of the Dataset\n",
    "        for val in values_aggregated:\n",
    "            sepal_length_agg_hist += val[0][0] # sepal length\n",
    "            sepal_length_agg_bin += val[1][0]\n",
    "            sepal_width_agg_hist += val[0][1] # sepal width\n",
    "            sepal_width_agg_bin += val[1][1]\n",
    "\n",
    "        dict_result = {\n",
    "            'sepal_length_h': sepal_length_agg_hist,\n",
    "            'sepal_width_h': sepal_width_agg_hist,\n",
    "            'sepal_length_b': sepal_length_agg_bin,\n",
    "            'sepal_width_b': sepal_width_agg_bin\n",
    "        }\n",
    "\n",
    "        ndarr = np.concatenate(\n",
    "            ([\"Sepal Length\"], sepal_length_agg_hist, [\"Sepal Width\"], sepal_width_agg_hist)\n",
    "        )\n",
    "        return ndarrays_to_parameters(ndarr), dict_result\n",
    "\n",
    "    def evaluate(\n",
    "            self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        agg_hist = [arr.item() for arr in parameters_to_ndarrays(parameters)]\n",
    "        return 0, {}\n",
    "\n",
    "    def configure_evaluate(\n",
    "            self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        pass\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "            self,\n",
    "            server_round: int,\n",
    "            results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "            failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4\n",
    "\n",
    "The built-in Flower Strategies provide way to send the config dictionary from server to clients, and it works similarly to the way server-side evaluation works. We provide a function to the strategy, and the strategy calls this function for every round of federated learning:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fit_config(server_round) -> Dict:\n",
    "    \"\"\"Send round number to client.\"\"\"\n",
    "    config = {\n",
    "        \"server_round\": server_round\n",
    "    }\n",
    "    return config\n",
    "\n",
    "# Define the strategy\n",
    "strategy = AggregateHistogram()\n",
    "\n",
    "# Simulation configuration\n",
    "# Check the Flower Framework documentation for more details about Flower Simulations\n",
    "# and how to setup the client_resources\n",
    "client_resources = {\"num_cpus\": 1}\n",
    "num_clients = NUM_CLIENTS\n",
    "num_rounds = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5\n",
    "\n",
    "The last step is the actual call `start_simulation` which starts the simulation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = fl.simulation.start_simulation(\n",
    "    strategy=strategy, # the strategy that will construct a client\n",
    "    client_fn=client_fn, # a function to construct a client\n",
    "    num_clients=num_clients, # total number of clients in the experiment\n",
    "    config=fl.server.ServerConfig(num_rounds=1), #let's run for 5 rounds\n",
    "    client_resources=client_resources,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6\n",
    "\n",
    "Analysing the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Draw the global aggregated histogram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aggregated histogram values\n",
    "length = result.metrics_distributed_fit.get('sepal_length_h')[0][1]\n",
    "width = result.metrics_distributed_fit.get('sepal_width_h')[0][1]\n",
    "\n",
    "# Aggregated bin values\n",
    "length_b = result.metrics_distributed_fit.get('sepal_length_b')[0][1]\n",
    "width_b = result.metrics_distributed_fit.get('sepal_width_b')[0][1]\n",
    "\n",
    "# Standard bins\n",
    "num_bins = 10\n",
    "# Calculate the centers of the bins for plotting\n",
    "bin_centers_l = (length_b[:-1] + length_b[1:]) / 2\n",
    "bin_centers_w = (width_b[:-1] + width_b[1:]) / 2\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.4\n",
    "\n",
    "# Adjusting bar positions for side-by-side plotting\n",
    "bar_positions_length = bin_centers_l - bar_width / 2\n",
    "bar_positions_width = bin_centers_w + bar_width / 2\n",
    "\n",
    "# Create the figure and subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot bars for Sepal Length\n",
    "ax1.bar(bar_positions_length, length, width=bar_width, color='blue', alpha=0.7, edgecolor='black', label='Length')\n",
    "ax1.set_title('Sepal Length')\n",
    "ax1.set_xlabel('Value')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xticks(bin_centers_l)\n",
    "\n",
    "# Plot bars for Sepal Width\n",
    "ax2.bar(bar_positions_width, width, width=bar_width, color='green', alpha=0.7, edgecolor='black', label='Width')\n",
    "ax2.set_title('Sepal Width')\n",
    "ax2.set_xlabel('Value')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_xticks(bin_centers_w)\n",
    "\n",
    "# Adjust layout to avoid overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the graph\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
