{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Get Started with Flower Framework\n",
        "\n",
        "Welcome to Federated Learning Tutorial using Flower Framework. Flower is a unified approach to federated learning, analytics, and evaluation. Open source, python, and easy to learn and personalize.\n",
        "\n",
        "https://flower.ai/"
      ],
      "metadata": {
        "collapsed": false,
        "id": "patF0uwCWjaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Preparation\n",
        "\n",
        "Before we begin with any actual code, let's make sure that we have everything we need.\n",
        "\n",
        "### Instaling dependencies\n",
        "First, we should install the necessary packages"
      ],
      "metadata": {
        "id": "s4VRMk-vZKP8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "# Linux\n",
        "!pip install -q flwr[simulation] flwr_datasets[vision] matplotlib\n",
        "\n",
        "# MacOs\n",
        "#!pip3 install -U 'flwr[simulation]' torch torchvision scipy"
      ],
      "metadata": {
        "id": "kFrw3tmbWjaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
      ],
      "metadata": {
        "id": "VkOhnSiq-HZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "disable_progress_bar()"
      ],
      "metadata": {
        "id": "l9QJfmzK-UPt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is possible to switch to a runtime that has GPU acceleration enabled (on Google Colab: Runtime > Change runtime type > Hardware accelerator: GPU > Save). Note, however, that Google Colab is not always able to offer GPU acceleration. If you see an error related to GPU availability in one of the following sections, consider switching back to CPU-based execution by setting DEVICE = torch.device(\"cpu\"). If the runtime has GPU acceleration enabled, you should see the output Training on cuda, otherwise it'll say Training on cpu."
      ],
      "metadata": {
        "id": "v5lpiayB-Xq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the data\n",
        "\n",
        "Federated learning can be applied to many different types of tasks across different domains. In this tutorial, we introduce federated learning by training a simple Linear Regression on the popular Abalone dataset. Abalone can be used in classification and regression tasks using 9 features: Sex, Length, Diameter, Height, Whole_weight, Shucked_weight, Viscera_weight, Shell_weight, and Rings."
      ],
      "metadata": {
        "id": "mC9VXsYY-ilX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We simulate having multiple datasets from multiple organizations (also called the \"cross-silo\" setting in federated learning) by splitting the original Abalone dataset into multiple partitions. Each partition will represent the data from a single organization. We're doing this purely for experimentation purposes.\n",
        "\n",
        "Each organization will act as a client in the federated learning system. So having 3 organizations participate in a federation means having 3 clients connected to the federated learning server.\n"
      ],
      "metadata": {
        "id": "e6NDMtfXAcHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now create the Federated Dataset abstraction that from flwr-datasets that partitions the Abalone. We will create small training and test set for each edge device and wrap each of them into a PyTorch DataLoader:"
      ],
      "metadata": {
        "id": "Rf89sMcRAy8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_datasets():\n",
        "  # URL dataset Abalone at UCI\n",
        "  url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
        "\n",
        "  # Name of columns in the Abalone dataset\n",
        "  columns = [\"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole_weight\", \"Shucked_weight\",\n",
        "            \"Viscera_weight\", \"Shell_weight\", \"Rings\"]\n",
        "\n",
        "  # Downloading the dataset\n",
        "  response = requests.get(url)\n",
        "  response.raise_for_status()  # Verifica se a requisição foi bem sucedida\n",
        "\n",
        "  # Saving content to a local file (optional)\n",
        "  with open(\"abalone.data\", \"wb\") as file:\n",
        "      file.write(response.content)\n",
        "\n",
        "  # Loading the dataset into a Pandas DataFrame\n",
        "  df = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "  # Using numpy array_split to split DataFrame into NUM_CLIENTS parts\n",
        "  partition = np.array_split(df, NUM_CLIENTS)\n",
        "\n",
        "  trainloaders = []\n",
        "  testloaders = []\n",
        "  # Splitting each partition into training and testing sets\n",
        "  for i, part in enumerate(partition):\n",
        "    trainloaders, testloaders = train_test_split(part, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
        "\n",
        "  return trainloaders, testloaders\n",
        "\n",
        "\n",
        "# trainloaders, valloaders, testloader = load_datasets()\n",
        "load_datasets()"
      ],
      "metadata": {
        "id": "_9moWzo8A5SF",
        "outputId": "a7adc779-f1c5-47e4-d5cc-1feebc2b629c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(     Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
              " 3528   I   0.350     0.265   0.085        0.1735          0.0775   \n",
              " 3247   F   0.610     0.495   0.190        1.2130          0.4640   \n",
              " 3769   F   0.560     0.430   0.145        0.8980          0.3895   \n",
              " 3462   F   0.625     0.470   0.170        1.2550          0.5250   \n",
              " 3946   M   0.525     0.410   0.165        0.8005          0.2635   \n",
              " ...   ..     ...       ...     ...           ...             ...   \n",
              " 3880   I   0.380     0.300   0.100        0.2860          0.1305   \n",
              " 3915   I   0.560     0.445   0.165        1.0285          0.4535   \n",
              " 4079   M   0.550     0.385   0.130        0.7275          0.3430   \n",
              " 3645   I   0.475     0.335   0.100        0.4425          0.1895   \n",
              " 3911   I   0.355     0.270   0.100        0.2160          0.0830   \n",
              " \n",
              "       Viscera_weight  Shell_weight  Rings  \n",
              " 3528          0.0340         0.056      6  \n",
              " 3247          0.3060         0.365     15  \n",
              " 3769          0.2325         0.245      9  \n",
              " 3462          0.2415         0.405     10  \n",
              " 3946          0.1985         0.250     13  \n",
              " ...              ...           ...    ...  \n",
              " 3880          0.0560         0.090      7  \n",
              " 3915          0.2530         0.275     11  \n",
              " 4079          0.1625         0.190      8  \n",
              " 3645          0.0860         0.135      9  \n",
              " 3911          0.0370         0.075     10  \n",
              " \n",
              " [1113 rows x 9 columns],\n",
              "      Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
              " 3814   I   0.380     0.275   0.095        0.2425          0.1060   \n",
              " 2953   F   0.645     0.520   0.170        1.1970          0.5260   \n",
              " 4159   F   0.560     0.440   0.135        0.8025          0.3500   \n",
              " 3773   F   0.575     0.460   0.150        0.9270          0.3330   \n",
              " 3238   M   0.695     0.530   0.150        1.4770          0.6375   \n",
              " ...   ..     ...       ...     ...           ...             ...   \n",
              " 2940   M   0.625     0.490   0.120        0.8765          0.4560   \n",
              " 3095   M   0.530     0.415   0.120        0.7060          0.3355   \n",
              " 4087   I   0.595     0.475   0.155        0.9840          0.4865   \n",
              " 3983   F   0.585     0.450   0.125        0.8740          0.3545   \n",
              " 3486   F   0.505     0.475   0.160        1.1155          0.5090   \n",
              " \n",
              "       Viscera_weight  Shell_weight  Rings  \n",
              " 3814          0.0485        0.2100      6  \n",
              " 2953          0.2925        0.3170     11  \n",
              " 4159          0.1615        0.2590      9  \n",
              " 3773          0.2070        0.2985      9  \n",
              " 3238          0.3025        0.4300     14  \n",
              " ...              ...           ...    ...  \n",
              " 2940          0.1800        0.2330     10  \n",
              " 3095          0.1635        0.1345      9  \n",
              " 4087          0.1840        0.2755     10  \n",
              " 3983          0.2075        0.2250      6  \n",
              " 3486          0.2390        0.3065      8  \n",
              " \n",
              " [279 rows x 9 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Flower Client"
      ],
      "metadata": {
        "id": "lLOd_wKsOFvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, X_train, y_train, X_test, y_test):\n",
        "        self.model = LogisticRegression(max_iter=100)\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return [val for _, val in sorted(self.model.get_params().items())]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        params_dict = {k: v for k, v in zip(sorted(self.model.get_params().keys()), parameters)}\n",
        "        self.model.set_params(**params_dict)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.fit(self.X_train, self.y_train)\n",
        "        return self.get_parameters(), len(self.X_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        y_pred = self.model.predict(self.X_test)\n",
        "        loss = 1 - accuracy_score(self.y_test, y_pred)\n",
        "        return loss, len(self.X_test), {}"
      ],
      "metadata": {
        "id": "SufAPyiYOFgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the Virtual Client Engine"
      ],
      "metadata": {
        "id": "WbAryD6NOPO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    net = Net().to(DEVICE)\n",
        "\n",
        "    # Load data (CIFAR-10)\n",
        "    # Note: each client gets a different trainloader/valloader, so each client\n",
        "    # will train and evaluate on their own unique data\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "\n",
        "    # Create a  single Flower client representing a single organization\n",
        "    return FlowerClient(net, trainloader, valloader).to_client()"
      ],
      "metadata": {
        "id": "C4_MPS4YOTcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start the training"
      ],
      "metadata": {
        "id": "ed1ovJDoOX2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
        "    min_fit_clients=10,  # Never sample less than 10 clients for training\n",
        "    min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "    min_available_clients=10,  # Wait until all 10 clients are available\n",
        ")\n",
        "\n",
        "# Specify the resources each of your clients need. By default, each\n",
        "# client will be allocated 1x CPU and 0x GPUs\n",
        "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
        "if DEVICE.type == \"cuda\":\n",
        "    # here we are assigning an entire GPU for each client.\n",
        "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0}\n",
        "    # Refer to our documentation for more details about Flower Simulations\n",
        "    # and how to setup these `client_resources`.\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")\n",
        "\n",
        "\n",
        "def start_server():\n",
        "    strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=1.0,\n",
        "        min_fit_clients=2,\n",
        "        min_evaluate_clients=2,\n",
        "        min_available_clients=2,\n",
        "    )\n",
        "    fl.server.start_server(config={\"num_rounds\": 3}, strategy=strategy)\n"
      ],
      "metadata": {
        "id": "MDH8GbikOaak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Accuracy"
      ],
      "metadata": {
        "id": "ixkkgwjuOhgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "xM8U9eY3OkzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Simulation"
      ],
      "metadata": {
        "id": "npQLj8RdOpM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ],
      "metadata": {
        "id": "oQpBA4ysOuz0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}